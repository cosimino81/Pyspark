{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset describing a group of US Universities. The dataset has the features of universities and labeled either Private or Public. The aim of the project is to create a machine learning model in order to classify from the features if a university is Private or Public. In order to do that I will use the Tree Methods Classifiers: DecisionTreeClassifier, GBTClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "root\n",
    " |-- School: string (nullable = true)\n",
    " |-- Private: string (nullable = true)\n",
    " |-- Apps: integer (nullable = true)\n",
    " |-- Accept: integer (nullable = true)\n",
    " |-- Enroll: integer (nullable = true)\n",
    " |-- Top10perc: integer (nullable = true)\n",
    " |-- Top25perc: integer (nullable = true)\n",
    " |-- F_Undergrad: integer (nullable = true)\n",
    " |-- P_Undergrad: integer (nullable = true)\n",
    " |-- Outstate: integer (nullable = true)\n",
    " |-- Room_Board: integer (nullable = true)\n",
    " |-- Books: integer (nullable = true)\n",
    " |-- Personal: integer (nullable = true)\n",
    " |-- PhD: integer (nullable = true)\n",
    " |-- Terminal: integer (nullable = true)\n",
    " |-- S_F_Ratio: double (nullable = true)\n",
    " |-- perc_alumni: integer (nullable = true)\n",
    " |-- Expend: integer (nullable = true)\n",
    " |-- Grad_Rate: integer (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of the spark session\n",
    "spark = SparkSession.builder.appName('treeMethods').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = spark.read.csv('College.csv', inferSchema= True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic exploration\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(School='Abilene Christian University', Private='Yes', Apps=1660, Accept=1232, Enroll=721, Top10perc=23, Top25perc=52, F_Undergrad=2885, P_Undergrad=537, Outstate=7440, Room_Board=3300, Books=450, Personal=2200, PhD=70, Terminal=78, S_F_Ratio=18.1, perc_alumni=12, Expend=7041, Grad_Rate=60)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a look to the data let's assenbler the features into a dense vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import of the vector assembler method\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the object\n",
    "# All the input column will be the features i will use to build the model\n",
    "assembler = VectorAssembler(inputCols=['Apps','Accept','Enroll','Top10perc','Top25perc','F_Undergrad','P_Undergrad','Outstate',\n",
    "                                       'Room_Board','Books','Personal','PhD','Terminal','S_F_Ratio','perc_alumni','Expend','Grad_Rate'], \n",
    "                            outputCol='features') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I transform the dataframe using the structure of the assembler\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if the \"features\" column has been created\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the targhet variable \"Private\" column is in a string type, our classifiers can't works on strings. In order to face this problem we have to convert the string in integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the StringIndexer mathod in order to convert the strings\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the object\n",
    "# Here I pass in input the column I want to convert\n",
    "# The output column with carry the conversion\n",
    "indexer = StringIndexer(inputCol='Private', outputCol='PrivateIndex')\n",
    "\n",
    "# Converting the dataframe\n",
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the conversion\n",
    "output_fixed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we can see that the \"PrivateIndex\" has been created and the values inside of it are double."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our dataframe ready to use. The next steps will be to reduce our dataframe and create a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I take only the columns i need for the models\n",
    "final_data = output_fixed.select('features', 'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of training set and test set\n",
    "training_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import of the models and Pipeline method\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier)\n",
    "#from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the models\n",
    "# 1) Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier(labelCol='PrivateIndex', featuresCol='features')\n",
    "\n",
    "# 2) RandomForestClassifier\n",
    "# In this case I decide the number of trees I want to build\n",
    "rfc = RandomForestClassifier(labelCol='PrivateIndex', featuresCol='features', numTrees=150)\n",
    "\n",
    "# 3) GBTClassifier\n",
    "gbc = GBTClassifier(labelCol='PrivateIndex', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of the models on the training data\n",
    "dtc_model = dtc.fit(training_data)\n",
    "rfc_model = rfc.fit(training_data)\n",
    "gbc_model = gbc.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the models on the test set\n",
    "dtc_predict = dtc_model.transform(test_data)\n",
    "rfc_predict = rfc_model.transform(test_data)\n",
    "gbc_predict = gbc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|            features|PrivateIndex|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|[81.0,72.0,51.0,3...|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[100.0,90.0,35.0,...|         0.0|[1.52190005518274...|[0.95451410360351...|       0.0|\n",
      "|[141.0,118.0,55.0...|         0.0|[1.30168608465055...|[0.93107829166289...|       0.0|\n",
      "|[150.0,130.0,88.0...|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[191.0,165.0,63.0...|         0.0|[1.52972462825513...|[0.95518872926387...|       0.0|\n",
      "|[202.0,184.0,122....|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[212.0,197.0,91.0...|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[213.0,166.0,85.0...|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[235.0,217.0,121....|         0.0|[1.52190005518274...|[0.95451410360351...|       0.0|\n",
      "|[244.0,198.0,82.0...|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[257.0,183.0,109....|         0.0|[1.21997117810615...|[0.91982283677071...|       0.0|\n",
      "|[261.0,192.0,111....|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[279.0,276.0,126....|         0.0|[1.36299677853380...|[0.93854315155825...|       0.0|\n",
      "|[281.0,266.0,139....|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[283.0,201.0,97.0...|         0.0|[1.52190005518274...|[0.95451410360351...|       0.0|\n",
      "|[285.0,280.0,208....|         1.0|[-0.5387574587083...|[0.25397658347742...|       1.0|\n",
      "|[291.0,245.0,126....|         0.0|[1.54581922085642...|[0.95654651829285...|       0.0|\n",
      "|[323.0,278.0,122....|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "|[325.0,284.0,95.0...|         0.0|[1.54102269983633...|[0.95614602991104...|       0.0|\n",
      "|[342.0,254.0,126....|         0.0|[1.54404859124739...|[0.95639908666787...|       0.0|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look on the decision tree model prediction before\n",
    "gbc_predict.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section I will use two evaluatin methods.\n",
    "1) The BinaryClassificationEvaluator\n",
    "2) The MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instancing the object for the classificatio\n",
    "# Here I pay attention to give in input the right colum where the evaluator will work\n",
    "# The metric we use will be the area under the ROC curve\n",
    "myBinaryEval = BinaryClassificationEvaluator(labelCol='PrivateIndex', metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the Area Under the Curve goes from 0 to 1. In any case an acceptable model must get a value upper than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC_accuracy =  0.9406991260923845\n"
     ]
    }
   ],
   "source": [
    "print ('DTC_accuracy = ', myBinaryEval.evaluate(dtc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC_accuracy =  0.970869746150646\n"
     ]
    }
   ],
   "source": [
    "#Dal valore sembra che il RandomForestClassifier funziona meglio\n",
    "print ('RFC_accuracy = ', myBinaryEval.evaluate(rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC_accuracy =  0.9508426966292134\n"
     ]
    }
   ],
   "source": [
    "print ('GBC_accuracy = ', myBinaryEval.evaluate(gbc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woow! All the models have high score close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc_predict.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_predict.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_predict.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In questo caso utilizzo il modulo che mi consente di lavorare su variabili multiclasse\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='PrivateIndex', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9353448275862069"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valuto l'accuratezza del RandomForestClassifier\n",
    "rfc_accuracy = acc_eval.evaluate(rfc_predict)\n",
    "rfc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9094827586206896"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valuto l'accuratezza del DecisionTreeClassifier\n",
    "dtc_accuracy = acc_eval.evaluate(dtc_predict)\n",
    "dtc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137931034482759"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valuto l'accuratezza del GBTClassifier\n",
    "gbc_accuracy = acc_eval.evaluate(gbc_predict)\n",
    "gbc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, even with the MulticlassClassificationEvaluator we get nice results! Now our model is ready to be used on new unlabeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for your attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "Decision Tree and Random Forest",
  "notebookId": 3968149267052535
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
