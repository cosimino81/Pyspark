{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Method the Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've been hired by a dog food company to try to predict why some batches of their dog food are spoiling much quicker than intended! Unfortunately this Dog Food company hasn't upgraded to the latest machinery, meaning that the amounts of the five preservative chemicals they are using can vary a lot, but which is the chemical that has the strongest effect? The dog food company first mixes up a batch of preservative that contains 4 different preservative chemicals (A,B,C,D) and then is completed with a \"filler\" chemical. The food scientists beelive one of the A,B,C, or D preservatives is causing the problem, but need your help to figure out which one! Use Machine Learning with RF to find out which parameter had the most predicitive power, thus finding out which chemical causes the early spoiling! So create a model and then find out how you can decide which chemical is the problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data description:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-Pres_A : Percentage of preservative A in the mix\n",
    "-Pres_B : Percentage of preservative B in the mix\n",
    "-Pres_C : Percentage of preservative C in the mix\n",
    "-Pres_D : Percentage of preservative D in the mix\n",
    "-Spoiled: Label indicating whether or not the dog food batch was spoiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a spark session\n",
    "spark = SparkSession.builder.appName('rf_project').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = spark.read.csv('dog_food.csv', inferSchema= True, header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "| 10|  3|13.0|  9|    1.0|\n",
      "|  8|  5|14.0|  5|    1.0|\n",
      "|  5|  8|12.0|  8|    1.0|\n",
      "|  6|  5|12.0|  9|    1.0|\n",
      "|  3|  3|12.0|  1|    1.0|\n",
      "|  9|  8|11.0|  3|    1.0|\n",
      "|  1| 10|12.0|  3|    1.0|\n",
      "|  1|  5|13.0| 10|    1.0|\n",
      "|  2| 10|12.0|  6|    1.0|\n",
      "|  1| 10|11.0|  4|    1.0|\n",
      "|  5|  3|12.0|  2|    1.0|\n",
      "|  4|  9|11.0|  8|    1.0|\n",
      "|  5|  1|11.0|  1|    1.0|\n",
      "|  4|  9|12.0| 10|    1.0|\n",
      "|  5|  8|10.0|  9|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the dataset is very simple, we don't need to normalize the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first thing to do is to vectorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the object\n",
    "# Here i take care about to give the right columns in input\n",
    "assembler = VectorAssembler(inputCols=['A', 'B', 'C', 'D'], outputCol='features')\n",
    "\n",
    "# Transforming the dataset\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- A: integer (nullable = true)\n",
      " |-- B: integer (nullable = true)\n",
      " |-- C: double (nullable = true)\n",
      " |-- D: integer (nullable = true)\n",
      " |-- Spoiled: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if the \"features\" column has been created\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step we can divide our \"output\" dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of training and test set\n",
    "training_data, test_data = output.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the random forest classifier\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the object\n",
    "# Here I pay attention to give the rigth column as parameter\n",
    "rfc = RandomForestClassifier(labelCol='Spoiled', featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step we create the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model on the training data\n",
    "rfc_model = rfc.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model we can use it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transforming the test data\n",
    "rfc_predict = rfc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+-------------------+--------------------+--------------------+----------+\n",
      "|  A|  B|   C|  D|Spoiled|           features|       rawPrediction|         probability|prediction|\n",
      "+---+---+----+---+-------+-------------------+--------------------+--------------------+----------+\n",
      "|  1|  1|12.0|  2|    1.0| [1.0,1.0,12.0,2.0]|          [1.0,19.0]|         [0.05,0.95]|       1.0|\n",
      "|  1|  1|12.0|  4|    1.0| [1.0,1.0,12.0,4.0]|          [1.0,19.0]|         [0.05,0.95]|       1.0|\n",
      "|  1|  1|13.0|  3|    1.0| [1.0,1.0,13.0,3.0]|          [1.0,19.0]|         [0.05,0.95]|       1.0|\n",
      "|  1|  2| 9.0|  4|    0.0|  [1.0,2.0,9.0,4.0]|          [18.0,2.0]|           [0.9,0.1]|       0.0|\n",
      "|  1|  3| 9.0|  8|    0.0|  [1.0,3.0,9.0,8.0]|          [19.0,1.0]|         [0.95,0.05]|       0.0|\n",
      "|  1|  4| 8.0|  5|    0.0|  [1.0,4.0,8.0,5.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1|  4| 9.0|  3|    0.0|  [1.0,4.0,9.0,3.0]|      [19.775,0.225]|[0.98874999999999...|       0.0|\n",
      "|  1|  4| 9.0|  6|    0.0|  [1.0,4.0,9.0,6.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1|  5| 8.0|  5|    0.0|  [1.0,5.0,8.0,5.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1|  5|12.0| 10|    1.0|[1.0,5.0,12.0,10.0]|          [0.0,20.0]|           [0.0,1.0]|       1.0|\n",
      "|  1|  5|13.0| 10|    1.0|[1.0,5.0,13.0,10.0]|          [0.0,20.0]|           [0.0,1.0]|       1.0|\n",
      "|  1|  6| 7.0|  8|    0.0|  [1.0,6.0,7.0,8.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1|  6| 8.0|  9|    0.0|  [1.0,6.0,8.0,9.0]|[17.9729729729729...|[0.89864864864864...|       0.0|\n",
      "|  1|  7| 7.0|  2|    0.0|  [1.0,7.0,7.0,2.0]|      [19.775,0.225]|[0.98874999999999...|       0.0|\n",
      "|  1|  7| 8.0|  4|    0.0|  [1.0,7.0,8.0,4.0]|      [19.775,0.225]|[0.98874999999999...|       0.0|\n",
      "|  1|  7|11.0|  9|    1.0| [1.0,7.0,11.0,9.0]|[0.14285714285714...|[0.00714285714285...|       1.0|\n",
      "|  1|  8| 6.0|  6|    0.0|  [1.0,8.0,6.0,6.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1|  8| 7.0| 10|    0.0| [1.0,8.0,7.0,10.0]|[18.7729729729729...|[0.93864864864864...|       0.0|\n",
      "|  1|  9| 9.0|  7|    0.0|  [1.0,9.0,9.0,7.0]|          [20.0,0.0]|           [1.0,0.0]|       0.0|\n",
      "|  1| 10|12.0|  3|    1.0|[1.0,10.0,12.0,3.0]|      [0.775,19.225]|   [0.03875,0.96125]|       1.0|\n",
      "+---+---+----+---+-------+-------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look up how is the prediction\n",
    "rfc_predict.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a first glance if we compare the \"Spoiled\" column with the \"prediction\" column seems that our model works good!\n",
    "Now let's evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instancing the object\n",
    "# In this case I pay attention to give the right column to evaluate end the metric we want to use\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"Spoiled\", predictionCol=\"prediction\", \n",
    "                                                  metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of more info about the accuracy: https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html#multiclass-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9724137931034482"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the evaluator on the dataframe\n",
    "acc_evaluator.evaluate(rfc_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice result! Our model has the 97% of accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now comes the most important part, we have to discove what preservatives is causing the problem.\n",
    "It seems a difficult task but in contrast it's very easy, we can solve it with the use of a simple function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0285, 1: 0.0324, 2: 0.9008, 3: 0.0382})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a sparse vector in a form of a dictionary. So if we look to the key:value pairs of the dictionary the most high value is 2:0.9008 that correspond to the preservative that cause the problem. If we want to understad to wich column it coincides it's very easy, it is the third column on the right, the \"C\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+---+-------+\n",
      "|  A|  B|   C|  D|Spoiled|\n",
      "+---+---+----+---+-------+\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "|  5|  6|12.0|  7|    1.0|\n",
      "|  6|  2|13.0|  6|    1.0|\n",
      "|  4|  2|12.0|  1|    1.0|\n",
      "|  4|  2|12.0|  3|    1.0|\n",
      "| 10|  3|13.0|  9|    1.0|\n",
      "|  8|  5|14.0|  5|    1.0|\n",
      "|  5|  8|12.0|  8|    1.0|\n",
      "|  6|  5|12.0|  9|    1.0|\n",
      "|  3|  3|12.0|  1|    1.0|\n",
      "|  9|  8|11.0|  3|    1.0|\n",
      "|  1| 10|12.0|  3|    1.0|\n",
      "|  1|  5|13.0| 10|    1.0|\n",
      "|  2| 10|12.0|  6|    1.0|\n",
      "|  1| 10|11.0|  4|    1.0|\n",
      "|  5|  3|12.0|  2|    1.0|\n",
      "|  4|  9|11.0|  8|    1.0|\n",
      "|  5|  1|11.0|  1|    1.0|\n",
      "|  4|  9|12.0| 10|    1.0|\n",
      "|  5|  8|10.0|  9|    1.0|\n",
      "+---+---+----+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks for your attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "Random Forest Project",
  "notebookId": 3968149267052570
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
